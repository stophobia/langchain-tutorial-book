{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 환경 변수 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3-7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System: \n",
      "     당신은 친절한 한국어 AI 어시스턴트입니다. \n",
      "     이전 대화 내용을 고려하여 사용자의 질문에 답변해주세요.\n",
      "     \n",
      "Human: 안녕하세요! 제 이름은 판다스입니다.\n",
      "AI: 안녕하세요, 판다스님! 어떤 도움이 필요하신가요?\n",
      "Human: 오늘 날씨에 대해 알려주세요.\n",
      "AI: 네, 오늘 날씨는 맑고 따뜻합니다.\n",
      "Human: 제 이름이 뭐였죠?\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "# ChatOpenAI 모델 초기화\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "# 프롬프트 템플릿 정의\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"\n",
    "     당신은 친절한 한국어 AI 어시스턴트입니다. \n",
    "     이전 대화 내용을 고려하여 사용자의 질문에 답변해주세요.\n",
    "     \"\"\"),\n",
    "    MessagesPlaceholder(variable_name=\"history\"),\n",
    "    (\"human\", \"{input}\")\n",
    "])\n",
    "\n",
    "\n",
    "# 가상의 대화 히스토리 생성\n",
    "history = [\n",
    "    HumanMessage(content=\"안녕하세요! 제 이름은 판다스입니다.\"),\n",
    "    AIMessage(content=\"안녕하세요, 판다스님! 어떤 도움이 필요하신가요?\"),\n",
    "    HumanMessage(content=\"오늘 날씨에 대해 알려주세요.\"),\n",
    "    AIMessage(content=\"네, 오늘 날씨는 맑고 따뜻합니다.\")\n",
    "]\n",
    "\n",
    "# 프롬프트 템플릿 포맷팅\n",
    "formatted_prompt = prompt.format(\n",
    "    history=history,\n",
    "    input=\"제 이름이 뭐였죠?\"\n",
    ")\n",
    "\n",
    "# 포맷팅된 프롬프트 출력\n",
    "print(formatted_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableWithMessageHistory(bound=RunnableBinding(bound=RunnableBinding(bound=RunnableAssign(mapper={\n",
       "  history: RunnableBinding(bound=RunnableLambda(_enter_history), kwargs={}, config={'run_name': 'load_history'}, config_factories=[])\n",
       "}), kwargs={}, config={'run_name': 'insert_history'}, config_factories=[])\n",
       "| RunnableBinding(bound=RunnableLambda(_call_runnable_sync), kwargs={}, config={'run_name': 'check_sync_or_async'}, config_factories=[]), kwargs={}, config={'run_name': 'RunnableWithMessageHistory'}, config_factories=[]), kwargs={}, config={}, config_factories=[], get_session_history=<function get_session_history at 0x116b6e3e0>, input_messages_key='input', history_messages_key='history', history_factory_config=[ConfigurableFieldSpec(id='session_id', annotation=<class 'str'>, name='Session ID', description='Unique identifier for a session.', default='', is_shared=True, dependencies=None)])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.chat_history import InMemoryChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "\n",
    "# 체인 생성\n",
    "chain = prompt | model\n",
    "\n",
    "# 메시지 히스토리를 저장할 딕셔너리\n",
    "store = {}\n",
    "\n",
    "# 세션 히스토리를 가져오는 함수\n",
    "def get_session_history(session_id: str):\n",
    "    if session_id not in store:\n",
    "        store[session_id] = InMemoryChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "# 메시지 히스토리를 포함한 실행 가능한 체인 생성\n",
    "chain_with_memory = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"history\"\n",
    ")\n",
    "\n",
    "# 메모리 체인 객체를 출력 \n",
    "chain_with_memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI: 안녕하세요, 판다스님! 반갑습니다. 어떻게 도와드릴까요?\n",
      "AI: 판다스님이라고 하셨습니다! 맞나요?\n"
     ]
    }
   ],
   "source": [
    "# 대화 실행\n",
    "config = {\"configurable\": {\"session_id\": \"user_001\"}}\n",
    "\n",
    "response1 = chain_with_memory.invoke(\n",
    "    {\"input\": \"안녕하세요! 제 이름은 판다스입니다.\"},\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "print(\"AI:\", response1.content)\n",
    "\n",
    "response2 = chain_with_memory.invoke(\n",
    "    {\"input\": \"제 이름이 뭐였죠?\"},\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "print(\"AI:\", response2.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI: 죄송하지만, 이전 대화 내용을 기억할 수 없어서 사용자의 이름을 알 수 없습니다. 다시 말씀해 주시면 좋겠습니다!\n"
     ]
    }
   ],
   "source": [
    "# 새로운 세션으로 대화 시작\n",
    "config_new = {\"configurable\": {\"session_id\": \"user_002\"}}\n",
    "\n",
    "response3 = chain_with_memory.invoke(\n",
    "    {\"input\": \"제 이름이 뭐였죠?\"},\n",
    "    config=config_new,\n",
    ")\n",
    "\n",
    "print(\"AI:\", response3.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3-11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI: 판다스님이라고 하셨습니다. 맞나요? 다른 질문이 있으시면 언제든지 말씀해 주세요!\n"
     ]
    }
   ],
   "source": [
    "# 다시 첫 번째 세션으로 대화를 이어서 시도 \n",
    "config = {\"configurable\": {\"session_id\": \"user_001\"}}\n",
    "\n",
    "response4 = chain_with_memory.invoke(\n",
    "    {\"input\": \"제 이름이 뭐였죠?\"},\n",
    "      config=config,\n",
    "      )\n",
    "\n",
    "# 답변 출력 \n",
    "print(\"AI:\", response4.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3-12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/steve2/Library/Caches/pypoetry/virtualenvs/langchain-book-AlsLlHcI-py3.11/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "# 사용자 메시지를 처리하고 AI 응답을 생성하는 함수\n",
    "def answer_invoke(message, history):\n",
    "    # Gradio의 history를 LangChain의 메시지 형식으로 변환\n",
    "    langchain_history = [\n",
    "        HumanMessage(content=h[0]) if i % 2 == 0 else AIMessage(content=h[0])\n",
    "        for i, h in enumerate(history)\n",
    "    ]\n",
    "    \n",
    "    # chain_with_memory 실행\n",
    "    config = {\"configurable\": {\"session_id\": \"gradio_user\"}}\n",
    "    response = chain_with_memory.invoke(\n",
    "        {\"input\": message, \"history\": langchain_history},\n",
    "        config=config\n",
    "    )\n",
    "    \n",
    "    # 생성된 응답 반환\n",
    "    return response.content\n",
    "\n",
    "# Gradio ChatInterface 객체 생성\n",
    "demo = gr.ChatInterface(\n",
    "    fn=answer_invoke,\n",
    "    title=\"한국어 AI 어시스턴트\",\n",
    "    description=\"이전 대화 내용을 기억하는 AI 어시스턴트입니다.\",\n",
    "    examples=[\"안녕하세요!\", \"제 이름은 판다스입니다.\", \"제 이름이 뭐였죠?\"],\n",
    "    retry_btn=\"다시 생성\",\n",
    "    undo_btn=\"되돌리기\",\n",
    "    clear_btn=\"대화 지우기\"\n",
    ")\n",
    "\n",
    "# Gradio 인터페이스 실행\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 7860\n"
     ]
    }
   ],
   "source": [
    "# Gradio 인터페이스 종료 \n",
    "demo.close ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-book-AlsLlHcI-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
