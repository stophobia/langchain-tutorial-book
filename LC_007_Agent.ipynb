{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 환경 변수 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/steve2/Library/Caches/pypoetry/virtualenvs/langchain-book-AlsLlHcI-py3.11/lib/python3.11/site-packages/langsmith/client.py:323: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt:\n",
      "[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a helpful assistant'), additional_kwargs={}), MessagesPlaceholder(variable_name='chat_history', optional=True), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={}), MessagesPlaceholder(variable_name='agent_scratchpad')]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "agent:\n",
      "first=RunnableAssign(mapper={\n",
      "  agent_scratchpad: RunnableLambda(lambda x: message_formatter(x['intermediate_steps']))\n",
      "}) middle=[ChatPromptTemplate(input_variables=['agent_scratchpad', 'input'], optional_variables=['chat_history'], input_types={'chat_history': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x11c69f380>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]], 'agent_scratchpad': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x11c69f380>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]}, partial_variables={'chat_history': []}, metadata={'lc_hub_owner': 'hwchase17', 'lc_hub_repo': 'openai-functions-agent', 'lc_hub_commit_hash': 'a1655024b06afbd95d17449f21316291e0726f13dcfaf990cc0d18087ad689a5'}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a helpful assistant'), additional_kwargs={}), MessagesPlaceholder(variable_name='chat_history', optional=True), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={}), MessagesPlaceholder(variable_name='agent_scratchpad')]), RunnableBinding(bound=ChatAnthropic(model='claude-3-haiku-20240307', anthropic_api_url='https://api.anthropic.com', anthropic_api_key=SecretStr('**********'), model_kwargs={}), kwargs={'tools': [{'name': 'tavily_search_results_json', 'description': 'A search engine optimized for comprehensive, accurate, and trusted results. Useful for when you need to answer questions about current events. Input should be a search query.', 'input_schema': {'properties': {'query': {'description': 'search query to look up', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}]}, config={}, config_factories=[])] last=ToolsAgentOutputParser()\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from langchain import hub\n",
    "from langchain_community.tools import TavilySearchResults\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain.agents import create_tool_calling_agent\n",
    "\n",
    "# hub에서 'hwchase17/openai-functions-agent' 프롬프트를 불러옴\n",
    "prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n",
    "\n",
    "# 프롬프트 메시지를 출력\n",
    "print(\"prompt:\")\n",
    "print(prompt.messages)\n",
    "print(\"-\" * 100)\n",
    "\n",
    "# Tavily 검색 결과 도구를 생성하고 최대 결과를 2개로 제한\n",
    "web_search = TavilySearchResults(max_results=2)\n",
    "tools = [web_search]\n",
    "\n",
    "# Claude-3 모델을 사용하여 ChatAnthropic 모델 생성\n",
    "model = ChatAnthropic(model_name=\"claude-3-haiku-20240307\")\n",
    "\n",
    "# 도구 호출 에이전트를 생성하여, 프롬프트와 도구들을 에이전트에 결합\n",
    "agent = create_tool_calling_agent(model, tools, prompt)\n",
    "\n",
    "# 에이전트를 출력\n",
    "print(\"agent:\")\n",
    "print(agent)\n",
    "print(\"-\" * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "verbose=False agent=RunnableMultiActionAgent(runnable=RunnableAssign(mapper={\n",
      "  agent_scratchpad: RunnableLambda(lambda x: message_formatter(x['intermediate_steps']))\n",
      "})\n",
      "| ChatPromptTemplate(input_variables=['agent_scratchpad', 'input'], optional_variables=['chat_history'], input_types={'chat_history': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x11c69f380>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]], 'agent_scratchpad': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x11c69f380>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]}, partial_variables={'chat_history': []}, metadata={'lc_hub_owner': 'hwchase17', 'lc_hub_repo': 'openai-functions-agent', 'lc_hub_commit_hash': 'a1655024b06afbd95d17449f21316291e0726f13dcfaf990cc0d18087ad689a5'}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a helpful assistant'), additional_kwargs={}), MessagesPlaceholder(variable_name='chat_history', optional=True), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={}), MessagesPlaceholder(variable_name='agent_scratchpad')])\n",
      "| RunnableBinding(bound=ChatAnthropic(model='claude-3-haiku-20240307', anthropic_api_url='https://api.anthropic.com', anthropic_api_key=SecretStr('**********'), model_kwargs={}), kwargs={'tools': [{'name': 'tavily_search_results_json', 'description': 'A search engine optimized for comprehensive, accurate, and trusted results. Useful for when you need to answer questions about current events. Input should be a search query.', 'input_schema': {'properties': {'query': {'description': 'search query to look up', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}]}, config={}, config_factories=[])\n",
      "| ToolsAgentOutputParser(), input_keys_arg=[], return_keys_arg=[], stream_runnable=True) tools=[TavilySearchResults(max_results=2, api_wrapper=TavilySearchAPIWrapper(tavily_api_key=SecretStr('**********')))]\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import AgentExecutor\n",
    "\n",
    "# 에이전트와 도구를 결합하여 AgentExecutor 객체 생성\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools) \n",
    "\n",
    "# AgentExecutor 객체 출력\n",
    "print(agent_executor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': '안녕하세요!',\n",
       " 'output': [{'text': '네, 안녕하세요! 무엇을 도와드릴까요?', 'type': 'text', 'index': 0}]}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 첫 번째 예시: 도구를 호출할 필요가 없을 때 에이전트의 응답\n",
    "agent_executor.invoke({\"input\": \"안녕하세요!\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': '2024년 하반기 애플 신제품은 무엇인가요?',\n",
       " 'output': [{'text': '\\n\\n2024년 하반기에 애플이 출시할 것으로 예상되는 신제품은 다음과 같습니다:\\n\\n- 애플 비전 프로(Apple Vision Pro) - 새로운 AR/VR 헤드셋 제품\\n- 아이폰 16 - 애플의 신형 스마트폰\\n- 아이패드 프로 OLED - OLED 디스플레이 적용된 프리미엄 태블릿 라인업\\n- 에어팟 4 - 애플의 무선 이어폰 새로운 세대\\n- 애플워치 10 - 애플워치의 10세대 모델로 주요 건강 기능 업그레이드 예정\\n\\n주요 제품들의 성능, 디자인, 가격 등 구체적인 사양 정보는 정식 출시 발표에 맞춰 알려질 것으로 보입니다. 애플은 신제품 라인업을 통해 2024년 하반기에 다양한 고객 니즈를 충족시키고자 노력할 것으로 예상됩니다.',\n",
       "   'type': 'text',\n",
       "   'index': 0}]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 웹 검색 도구를 호출해야 하는 예시를 실행\n",
    "agent_executor.invoke({\"input\": \"2024년 하반기 애플 신제품은 무엇인가요?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.chat_history import InMemoryChatMessageHistory\n",
    "\n",
    "# 세션별 대화 기록을 저장할 딕셔너리\n",
    "store = {}\n",
    "\n",
    "# session_id를 기반으로 대화 기록을 가져오거나 새로 생성하는 함수\n",
    "def get_session_history(session_id: str):\n",
    "    if session_id not in store:\n",
    "        store[session_id] = InMemoryChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "# store 출력\n",
    "print(store)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response: \n",
      "\n",
      "\n",
      "테슬라의 CEO이자 창업자는 일론 머스크(Elon Musk)입니다. 일론 머스크는 2008년부터 테슬라의 CEO를 맡고 있으며, 스페이스X, 솔라시티, 트위터, 더 보링 컴퍼니, 뉴런링크 등 다양한 회사를 이끌고 있는 기업가입니다. 그는 지속 가능한 에너지 기업인 테슬라를 이끌면서 전기 자동차, 배터리, 태양 에너지 사업을 성공적으로 펼치고 있습니다.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "store: \n",
      "{'test_001': InMemoryChatMessageHistory(messages=[HumanMessage(content='제 이름은 판다스입니다. 테슬라 회장은 누구인가요?', additional_kwargs={}, response_metadata={}), AIMessage(content='\\n\\n테슬라의 CEO이자 창업자는 일론 머스크(Elon Musk)입니다. 일론 머스크는 2008년부터 테슬라의 CEO를 맡고 있으며, 스페이스X, 솔라시티, 트위터, 더 보링 컴퍼니, 뉴런링크 등 다양한 회사를 이끌고 있는 기업가입니다. 그는 지속 가능한 에너지 기업인 테슬라를 이끌면서 전기 자동차, 배터리, 태양 에너지 사업을 성공적으로 펼치고 있습니다.', additional_kwargs={}, response_metadata={}, role='assistant')])}\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_core.messages import AIMessage\n",
    "\n",
    "# 메모리를 갖춘 에이전트 생성\n",
    "agent_with_chat_history = RunnableWithMessageHistory(\n",
    "     # 기존 에이전트 실행도구\n",
    "    agent_executor | (lambda x: AIMessage(content=x[\"output\"][0][\"text\"], role=\"assistant\")),               \n",
    "    get_session_history,           # 세션별 대화 기록을 관리하는 함수\n",
    "    input_messages_key=\"input\",    # 입력 대화를 저장할 키\n",
    "    history_messages_key=\"chat_history\"  # 대화 기록을 불러올 키\n",
    ")\n",
    "\n",
    "# 세션 ID를 지정\n",
    "config = {\"configurable\": {\"session_id\": \"test_001\"}}  \n",
    "\n",
    "# 첫 번째 대화: 새로운 세션에서 질문 \n",
    "response = agent_with_chat_history.invoke(\n",
    "    {\"input\": \"제 이름은 판다스입니다. 테슬라 회장은 누구인가요?\"}, \n",
    "    config=config\n",
    ")\n",
    "\n",
    "# 에이전트의 응답 출력\n",
    "print(\"response: \")\n",
    "print(response.content)\n",
    "print(\"-\"*100)\n",
    "\n",
    "# store 출력\n",
    "print(\"store: \")\n",
    "print(store)\n",
    "print(\"-\"*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6-7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response: \n",
      "죄송합니다. 제가 처음에 잘못 알아들었던 것 같습니다. 여러분의 이름이 판다스라고 말씀하셨네요. 감사합니다!\n",
      "----------------------------------------------------------------------------------------------------\n",
      "store: \n",
      "{'test_001': InMemoryChatMessageHistory(messages=[HumanMessage(content='제 이름은 판다스입니다. 테슬라 회장은 누구인가요?', additional_kwargs={}, response_metadata={}), AIMessage(content='\\n\\n테슬라의 CEO이자 창업자는 일론 머스크(Elon Musk)입니다. 일론 머스크는 2008년부터 테슬라의 CEO를 맡고 있으며, 스페이스X, 솔라시티, 트위터, 더 보링 컴퍼니, 뉴런링크 등 다양한 회사를 이끌고 있는 기업가입니다. 그는 지속 가능한 에너지 기업인 테슬라를 이끌면서 전기 자동차, 배터리, 태양 에너지 사업을 성공적으로 펼치고 있습니다.', additional_kwargs={}, response_metadata={}, role='assistant'), HumanMessage(content='제 이름은 무엇인가요?', additional_kwargs={}, response_metadata={}), AIMessage(content='죄송합니다. 제가 처음에 잘못 알아들었던 것 같습니다. 여러분의 이름이 판다스라고 말씀하셨네요. 감사합니다!', additional_kwargs={}, response_metadata={}, role='assistant')])}\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 이전 대화를 기억하는지 확인\n",
    "response = agent_with_chat_history.invoke(  \n",
    "    {\"input\": \"제 이름은 무엇인가요?\"},\n",
    "    config=config\n",
    ")\n",
    "\n",
    "# 에이전트의 응답 출력\n",
    "print(\"response: \")\n",
    "print(response.content)\n",
    "print(\"-\"*100)\n",
    "\n",
    "# store 출력\n",
    "print(\"store: \")\n",
    "print(store)\n",
    "print(\"-\"*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "2024년 테슬라 회장은 누구인가요? 한국어로 답변하세요.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "[{'id': 'toolu_013bo1nBEwoAgQoeZhUMcMCs', 'input': {'query': '2024년 테슬라 회장'}, 'name': 'tavily_search_results_json', 'type': 'tool_use'}]\n",
      "Tool Calls:\n",
      "  tavily_search_results_json (toolu_013bo1nBEwoAgQoeZhUMcMCs)\n",
      " Call ID: toolu_013bo1nBEwoAgQoeZhUMcMCs\n",
      "  Args:\n",
      "    query: 2024년 테슬라 회장\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: tavily_search_results_json\n",
      "\n",
      "[{\"url\": \"https://www.chosun.com/economy/tech_it/2024/02/02/IT65WYOF6FF5NCKXANQPZU57Q4/\", \"content\": \"2024년 9월 26일(목) ... 지난 2018년 테슬라 이사회는 머스크에 대해 560억달러 규모의 보상 패키지 지급안을 승인했다. 이후 테슬라 주식 9주를 가진 소액 주주 리처드 토네타는 \\\"이사회가 승인한 보상 패키지는 역사상 유례없는 수준의 고액으로 과도하게 많다\\\"며 ...\"}, {\"url\": \"https://biz.chosun.com/international/international_general/2024/06/14/CGTTU7MPJBCDJA5OMO3NSKLBME/\", \"content\": \"테슬라 주주총회서 67兆 규모 머스크 스톡옵션 보상안 재승인 ... 2024년 9월 24일(화) ... 해당 보상안은 지난 2018년 이사회와 주주총회를 거쳐 ...\"}]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "위 검색 결과를 종합하면, 2024년 현재 테슬라의 회장은 일론 머스크인 것으로 보입니다. 2018년에 테슬라 이사회가 머스크에게 560억 달러 규모의 보상 패키지를 승인했고, 이후 2024년 6월 주주총회에서도 67조 원 규모의 스톡옵션 보상안이 재승인되었기 때문입니다. 따라서 2024년 현재에도 일론 머스크가 테슬라 회장직을 유지하고 있는 것으로 확인됩니다.\n"
     ]
    }
   ],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "# LLM에 도구 바인딩하여 ReAct 에이전트 생성 \n",
    "agent = create_react_agent(model, tools=tools)\n",
    "\n",
    "# 입력 값 정의 \n",
    "inputs = {\"messages\": [(\"user\", \"2024년 테슬라 회장은 누구인가요? 한국어로 답변하세요.\")]}\n",
    "\n",
    "# 에이전트의 응답을 스트리밍 방식으로 출력  \n",
    "for s in agent.stream(inputs, stream_mode=\"values\"):\n",
    "    message = s[\"messages\"][-1]\n",
    "    if isinstance(message, tuple):\n",
    "        print(message)\n",
    "    else:\n",
    "        message.pretty_print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-book-AlsLlHcI-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
